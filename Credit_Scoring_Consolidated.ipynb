{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M-ATSE_P1AA"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTAÇÃO DAS BIBLIOTECAS\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scipy.stats import ks_2samp\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNÇÕES AUXILIARES\n",
        "# =============================================================================\n",
        "\n",
        "def calcular_ks(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula a estatística KS (Kolmogorov-Smirnov).\n",
        "\n",
        "    Args:\n",
        "        y_true: Array numpy ou lista contendo os valores reais (0 ou 1).\n",
        "        y_pred: Array numpy ou lista contendo as probabilidades previstas (entre 0 e 1).\n",
        "\n",
        "    Returns:\n",
        "        O valor da estatística KS.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
        "    data_bom = data[data['y_true'] == 0]['y_pred']\n",
        "    data_mau = data[data['y_true'] == 1]['y_pred']\n",
        "    ks = ks_2samp(data_bom, data_mau).statistic\n",
        "    return ks\n",
        "\n",
        "def calcular_gini(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula o GINI a partir das previsões e valores reais.\n",
        "\n",
        "    Args:\n",
        "        y_true: Array numpy ou lista contendo os valores reais (0 ou 1).\n",
        "        y_pred: Array numpy ou lista contendo as probabilidades previstas (entre 0 e 1).\n",
        "\n",
        "    Returns:\n",
        "        O valor do GINI.\n",
        "    \"\"\"\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "    gini = 2 * auc - 1\n",
        "    return gini\n",
        "\n",
        "def fill_missing_values(df, column, filler_values):\n",
        "    \"\"\"\n",
        "    Preenche valores ausentes (NaN) em uma coluna de um DataFrame com uma lista de valores,\n",
        "    distribuindo esses valores uniformemente.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): O DataFrame a ser modificado.\n",
        "        column (str): O nome da coluna a ser preenchida.\n",
        "        filler_values (list): Uma lista de valores para preencher os NaNs.\n",
        "    \"\"\"\n",
        "    nan_count = df[column].isnull().sum()\n",
        "\n",
        "    if nan_count > 0:\n",
        "        for i, filler in enumerate(filler_values):\n",
        "            limit = int(nan_count // len(filler_values)) if i < len(filler_values) - 1 else None\n",
        "            df[column].fillna(filler, limit=limit, inplace=True)\n",
        "\n",
        "    print(f\"Valores NaN restantes na coluna '{column}': {df[column].isnull().sum()}\")\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred_proba):\n",
        "    \"\"\"Plota a curva ROC.\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Taxa de Falsos Positivos')\n",
        "    plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "    plt.title('Curva ROC')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_credit_model(y_true, y_pred, y_pred_proba):\n",
        "    \"\"\"Avalia modelo de credit scoring com métricas específicas.\"\"\"\n",
        "    ks = calcular_ks(y_true, y_pred_proba)\n",
        "    gini = calcular_gini(y_true, y_pred_proba)\n",
        "\n",
        "    print(f\"KS Score: {ks:.4f}\")\n",
        "    print(f\"Gini Index: {gini:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    plot_roc_curve(y_true, y_pred_proba)\n",
        "\n",
        "def select_important_features(model, feature_names, threshold=0.1):\n",
        "    \"\"\"Seleciona features importantes baseado nos coeficientes do modelo.\"\"\"\n",
        "    coef_abs = abs(model.coef_[0])\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': coef_abs\n",
        "    })\n",
        "\n",
        "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "    selected_features = feature_importance[feature_importance['importance'] > threshold]['feature'].tolist()\n",
        "\n",
        "    return selected_features, feature_importance"
      ],
      "metadata": {
        "id": "lQCL8b-8QwkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PREPARAÇÃO E TRATAMENTO DE DADOS\n",
        "# =============================================================================\n",
        "\n",
        "# Importação dos dados\n",
        "df = pd.read_csv('/content/drive/MyDrive/DATA_VIKING/credit_risk.csv')\n",
        "print(\"Dados carregados. Shape:\", df.shape)\n",
        "\n",
        "# Visualização inicial\n",
        "print(\"\\nPrimeiras linhas:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInformações do DataFrame:\")\n",
        "print(df.info())\n",
        "\n",
        "# Tratamento de valores nulos\n",
        "# Substituindo valores NaN na coluna 'saving_accounts', pela variável 'little'\n",
        "df['saving_accounts'].fillna('little', inplace=True)\n",
        "# Substituindo valores NaN na coluna 'checking_account', dividindo entre 'little' e 'moderate'\n",
        "fill_missing_values(df, 'checking_account', ['little', 'moderate'])\n",
        "\n",
        "# Codificação de variáveis categóricas\n",
        "df['risk'] = df['risk'].map({'good': 1, 'bad': 0})\n",
        "df['sex'] = df['sex'].map({'male': 1, 'female': 0})\n",
        "\n",
        "# Criação de features de tempo\n",
        "df['month'] = df['reference'].str.split('-').str[1].astype(int)\n",
        "df['year'] = df['reference'].str.split('-').str[0].astype(int)\n",
        "\n",
        "# Remoção de colunas desnecessárias\n",
        "df = df.drop(columns=['Unnamed: 0', 'cpf', 'income', 'reference'])\n",
        "\n",
        "# One-hot encoding para variáveis categóricas\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    df = pd.get_dummies(df, columns=[column], drop_first=True, dtype=int)\n",
        "\n",
        "# Separação em features e target\n",
        "df_x = df.drop(columns=['risk'])\n",
        "df_y = df['risk']"
      ],
      "metadata": {
        "id": "MIZBpVRXQ7E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODELO I - REGRESSÃO LOGÍSTICA BÁSICA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODELO I - REGRESSÃO LOGÍSTICA BÁSICA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Divisão treino-teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinamento do modelo\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "y_pred_proba_1 = y_pred_proba[:, 1]\n",
        "\n",
        "# Avaliação\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Métricas de credit scoring\n",
        "ks = calcular_ks(y_test, y_pred_proba_1)\n",
        "gini = calcular_gini(y_test, y_pred_proba_1)\n",
        "print(f\"\\nKS: {ks:.4f}\")\n",
        "print(f\"GINI: {gini:.4f}\")\n",
        "\n",
        "# Curva ROC\n",
        "plot_roc_curve(y_test, y_pred_proba_1)\n",
        "\n",
        "# Coeficientes do modelo\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': df_x.columns,\n",
        "    'Coefficient': model.coef_[0]\n",
        "}).sort_values('Coefficient', ascending=False)\n",
        "print(\"\\nCoeficientes do modelo:\")\n",
        "print(coef_df)\n",
        "\n",
        "# Validação cruzada\n",
        "cv_scores = cross_val_score(model, df_x, df_y, cv=5)\n",
        "print(\"\\nScores da validação cruzada:\", cv_scores)\n",
        "print(\"Média da validação cruzada:\", cv_scores.mean())\n",
        "\n",
        "# Grid Search\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"\\nMelhores parâmetros:\", grid_search.best_params_)\n",
        "print(\"Melhor score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "PjVe-wG1Q_x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TRATAMENTO DE DESBALANCEAMENTO\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRATAMENTO DE DESBALANCEAMENTO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Pipeline de balanceamento\n",
        "balancing_pipeline = ImbPipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('undersampling', RandomUnderSampler(random_state=42))\n",
        "])\n",
        "\n",
        "# Aplicar balanceamento\n",
        "X_train_balanced, y_train_balanced = balancing_pipeline.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "WA7WDUJUREiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODELO II - COM BALANCEAMENTO\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODELO II - COM BALANCEAMENTO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Divisão treino-teste com dados balanceados\n",
        "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(\n",
        "    X_train_balanced, y_train_balanced, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Treinamento do modelo balanceado\n",
        "model_bal = LogisticRegression(class_weight='balanced')\n",
        "model_bal.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Previsões\n",
        "y_pred_bal = model_bal.predict(X_test_bal)\n",
        "y_pred_proba_bal = model_bal.predict_proba(X_test_bal)[:, 1]\n",
        "\n",
        "# Avaliação\n",
        "print(\"accuracy_score:\", accuracy_score(y_test_bal, y_pred_bal))\n",
        "print(\"precision_score:\", precision_score(y_test_bal, y_pred_bal))\n",
        "print(\"recall_score:\", recall_score(y_test_bal, y_pred_bal))\n",
        "print(\"f1_score:\", f1_score(y_test_bal, y_pred_bal))\n",
        "print(\"roc_auc_score:\", roc_auc_score(y_test_bal, y_pred_proba_bal))\n",
        "print(\"\\nconfusion_matrix:\\n\", confusion_matrix(y_test_bal, y_pred_bal))\n",
        "\n",
        "# Métricas de credit scoring\n",
        "ks_bal = calcular_ks(y_test_bal, y_pred_proba_bal)\n",
        "gini_bal = calcular_gini(y_test_bal, y_pred_proba_bal)\n",
        "print(f\"\\nKS (balanceado): {ks_bal:.4f}\")\n",
        "print(f\"GINI (balanceado): {gini_bal:.4f}\")"
      ],
      "metadata": {
        "id": "yVTQTfJHRH3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FEATURE ENGINEERING E SELEÇÃO\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FEATURE ENGINEERING E SELEÇÃO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Coeficientes do modelo balanceado para seleção de features\n",
        "coef_bal_df = pd.DataFrame({\n",
        "    'Feature': X_train_balanced.columns,\n",
        "    'Coefficient': model_bal.coef_[0]\n",
        "}).sort_values('Coefficient', ascending=False)\n",
        "\n",
        "print(\"Coeficientes do modelo balanceado:\")\n",
        "print(coef_bal_df)\n",
        "\n",
        "# Seleção de features importantes\n",
        "feature_names = list(X_train_balanced.columns)\n",
        "selected_features, feature_importance = select_important_features(model_bal, feature_names, threshold=0.1)\n",
        "\n",
        "print(f\"\\nFeatures selecionadas ({len(selected_features)}):\")\n",
        "print(selected_features)\n",
        "\n",
        "# Criar DataFrame com features selecionadas\n",
        "X_reduced = X_train_balanced[selected_features]\n",
        "y_reduced = y_train_balanced"
      ],
      "metadata": {
        "id": "xiJELr6rRL4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODELO III - COM FEATURES SELECIONADAS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODELO III - COM FEATURES SELECIONADAS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Divisão treino-teste com features selecionadas\n",
        "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(\n",
        "    X_reduced, y_reduced, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Treinamento do modelo com features selecionadas\n",
        "model_red = LogisticRegression()\n",
        "model_red.fit(X_train_red, y_train_red)\n",
        "\n",
        "# Previsões\n",
        "y_pred_red = model_red.predict(X_test_red)\n",
        "y_pred_proba_red = model_red.predict_proba(X_test_red)\n",
        "y_pred_proba_1_red = y_pred_proba_red[:, 1]\n",
        "\n",
        "# Avaliação\n",
        "print(\"Acurácia:\", accuracy_score(y_test_red, y_pred_red))\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test_red, y_pred_red))\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_test_red, y_pred_red))\n",
        "\n",
        "# Métricas de credit scoring\n",
        "ks_red = calcular_ks(y_test_red, y_pred_proba_1_red)\n",
        "gini_red = calcular_gini(y_test_red, y_pred_proba_1_red)\n",
        "print(f\"\\nKS (features selecionadas): {ks_red:.4f}\")\n",
        "print(f\"GINI (features selecionadas): {gini_red:.4f}\")"
      ],
      "metadata": {
        "id": "ZvjhQ8ayRScf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PIPELINE COMPLETO COM FEATURE ENGINEERING\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PIPELINE COMPLETO COM FEATURE ENGINEERING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Definir features numéricas (todas as colunas neste caso)\n",
        "numeric_features = df_x.columns.tolist()\n",
        "\n",
        "# Preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('scaler', StandardScaler(), numeric_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline completo\n",
        "model_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Grid Search com validação cruzada\n",
        "param_grid_complete = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__class_weight': ['balanced', None],\n",
        "    'classifier__solver': ['liblinear', 'saga'],\n",
        "    'classifier__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "grid_search_complete = GridSearchCV(\n",
        "    model_pipeline,\n",
        "    param_grid_complete,\n",
        "    cv=5,\n",
        "    scoring=['accuracy', 'f1', 'roc_auc'],\n",
        "    refit='roc_auc'\n",
        ")\n",
        "\n",
        "# Treinar grid search\n",
        "grid_search_complete.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores parâmetros (pipeline completo):\", grid_search_complete.best_params_)\n",
        "print(\"Melhor score (pipeline completo):\", grid_search_complete.best_score_)"
      ],
      "metadata": {
        "id": "JbMCMABnRW6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VALIDAÇÃO COM K-FOLD\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VALIDAÇÃO COM K-FOLD\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores_kf = cross_val_score(model_pipeline, df_x, df_y, cv=kf, scoring='roc_auc')\n",
        "\n",
        "print(\"Scores K-Fold:\", cv_scores_kf)\n",
        "print(\"Média K-Fold:\", cv_scores_kf.mean())\n",
        "print(\"Desvio padrão K-Fold:\", cv_scores_kf.std())"
      ],
      "metadata": {
        "id": "PZnHPWs4Rc5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RESULTADOS FINAIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTADOS FINAIS COMPARATIVOS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "resultados = pd.DataFrame({\n",
        "    'Modelo': ['Básico', 'Balanceado', 'Features Selecionadas', 'Pipeline Completo'],\n",
        "    'AUC': [\n",
        "        roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]),\n",
        "        roc_auc_score(y_test_bal, model_bal.predict_proba(X_test_bal)[:, 1]),\n",
        "        roc_auc_score(y_test_red, model_red.predict_proba(X_test_red)[:, 1]),\n",
        "        grid_search_complete.best_score_\n",
        "    ],\n",
        "    'KS': [ks, ks_bal, ks_red, np.nan],\n",
        "    'GINI': [gini, gini_bal, gini_red, np.nan]\n",
        "})\n",
        "\n",
        "print(resultados)\n",
        "\n",
        "print(\"\\nAnálise concluída!\")"
      ],
      "metadata": {
        "id": "OxAwXsFuRfhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}